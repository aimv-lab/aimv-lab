<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black" />
<meta name="renderer" content="webkit" />
<meta name="screen-orientation" content="portrait" />
<meta name="x5-orientation" content="portrait" />
<title>AIMV Laboratory|Artificial Intelligence and Machine Vision</title>
<link rel="stylesheet" type="text/css" href="css/style.css"/>
</head>
<body>

	<div class="top clearfix">
		<div class="header-navbar">
			<a href="index.html" target="_blank" class="logo fl"><img src="img/logo.png" /></a>
			<ul class="navbar clearfix fl">
				<li><a href="index.html" style="font-size: 16px;">首页</a></li>
				<li><a href="supervisor.html" style="font-size: 16px;">团队</a></li>
				<li><a href="direction.html" style="font-size: 16px;">科研方向</a></li>
				<li><a href="publication.html" style="font-size: 16px;">出版物</a></li>
				<li><a href="resource.html" style="font-size: 16px;">资源</a></li>
				<li><a href="news.html" style="font-size: 16px;">新闻</a></li>
				<li><a href="graduates.html" style="font-size: 16px;">毕业生</a></li>
				<li><a href="index_en.html" style="font-size: 16px;">English</a></li>
			</ul>
		</div>
	</div>

<div class="banner">
	<ul class="bannerfix slides clearfix">
    	<li>
    		<img class="bimg" src="img/slide/10.jpg" />
    	</li>
    	<li>
    		<img class="bimg" src="img/slide/2.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/11.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/4.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/5.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/6.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/7.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/8.jpg" />
    	</li>
		<li>
    		<img class="bimg" src="img/slide/9.jpg" />
    	</li>
	</ul>	
	<div class="bamnline"><span></span></div>
	
</div>
<div class="index-sec2">
	<div class="w1240">
		<div class="w1240 de-box">
			<div class="clearfix ">	
				<div class="detail-left">
					<div class="stace">
						<h1>团队介绍</h1>                    
						<div class="cont">
							<p style='text-align: justify'>
							人工智能与机器视觉（AIMV）实验室成立于2017年，旨在进行人工智能相关的研究和应用，主要专注于计算机视觉、图像/视频处理、模式识别、机器人、计算智能和机器学习。
							目前，AIMV实验室由6个学院、2个博士后、12名博士候选人和50多名硕士生组成，是一个包含数学、计算机工程、电子与控制工程和机械工程等多学科研究人员的交叉研究团队。
							在IEEE Conference on Computer Vision and Pattern Recognition, IEEE International Conference on Computer Vision, IEEE Trans. Image Processing, IEEE Trans. Fuzzy System, IEEE Trans. Cybernetics，SIGGRAPH等国内外顶级期刊及会议发表论文400多篇，
							申请发明专利40余项，其中授权美国专利5项，中国授权专利22项。	
						   </p>
						</div>                   
				   </div>  
				</div>
			 </div>
		</div>		
	</div>
</div>	

<div class="index-sec3">
	<div class="tit">
		<h2>最新成果</h2>
	</div>
	<div class="w1240">
		<div class="index-content">
			<div class="bd">
				<ul class="picList" style="list-style:none;"  >
					<li>
						<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10081014">
							<figure>
								<img src="img/gaozheng.jpg"/>
							</figure>
							<figcaption>
								<p class="p1">A Hybrid Method for Implicit Intention Inference
									Based on Punished-Weighted Naïve Bayes</p>
								<p class="p2">Gaze-based implicit intention inference
									provides a new human-robot interaction for people
									with disabilities to accomplish activities of daily living
									independently. Existing gaze-based intention inference is
									mainly implemented by the data-driven method without
									prior object information in intention expression, which
									yields low inference accuracy. Aiming to improve the
									inference accuracy, we propose a gaze-based hybrid
									method by integrating model-driven and data-driven
									intention inference tailored to disability ...</p>
							</figcaption>
						</a>
					</li>


					<li>
						<a href="https://arxiv.org/pdf/2209.05913.pdf">
							<figure>
								<img src="img/Dual Scale Single.jpg"/>
							</figure>
							<figcaption>
								<p class="p1">Dual-Scale Single Image Dehazing via Neural Augmentation</p>
								<p class="p2">Model-based single image dehazing algorithms restore haze-free images with sharp edges and rich details for real-world
									hazy images at the expense of low PSNR and SSIM values for synthetic hazy images. Data-driven ones restore haze-free images
									with high PSNR and SSIM values for synthetic hazy images but with low contrast, and even some remaining haze for realworld
									hazy images. In this paper, a novel single image dehazing algorithm is introduced by combining model-based and datadriven
									...</p>
							</figcaption>
						</a>
					</li>
					<li>
						<a href="https://doi.org/10.1016/j.patcog.2022.108900">
							<figure>
								<img src="img/AWGIF.png"/>
							</figure>
							<figcaption>
								<p class="p1">Adaptive weighted guided image filtering for depth enhancement in shape-from-focus</p>
								<p class="p2">Existing shape from focus (SFF) techniques cannot preserve depth edges and fine structural details
									from a sequence of multi-focus images. Moreover, noise in the sequence of multi-focus images affects
									the accuracy of the depth map. In this paper, a novel depth enhancement algorithm for the SFF based
									on an adaptive weighted guided image filtering (AWGIF) is proposed to address the above issues.The AWGIF is applied to decompose an initial depth map which is estimated by the traditional SFF
									into a base layer...</p>
							</figcaption>
						</a>
					</li> 

					<li>
						<a href="https://www.mdpi.com/2071-1050/14/22/15329">
							<figure>
								<img src="img/sustainability.jpg"/>
							</figure>
							<figcaption>
								<p class="p1">Water Column Detection Method at Impact Point Based on
									Improved YOLOv4 Algorithm</p>
								<p class="p2">For a long time, the water column at the impact point of a naval gun firing at the sea
									has mainly depended on manual detection methods for locating, which has problems such as low
									accuracy, subjectivity and inefficiency. In order to solve the above problems, this paper proposes
									a water column detection method based on an improved you-only-look-once version 4 (YOLOv4)
									algorithm. Firstly, the method detects the sea antenna through the Hoffman line detection method...</p>
							</figcaption>
						</a>
					</li>

					<li>
						<a href="https://oar.a-star.edu.sg/storage/d/d62ee21rxr/image-noise-level-estimation-via-kurtosis-test.pdf">
							<figure>
								<img src="img/noise test.png"/>
							</figure>
							<figcaption>
								<p class="p1">Image noise level estimation via kurtosis test</p>
								<p class="p2">Noise level estimation is a long-standing problem in image processing. 
									The challenge arises from the fact 7 that the estimation can be easily affected by 
									texture information. In this paper, a new noise level estimation method 8 via kurtosis
									 test is proposed, which is a normalized fourth-order moment. The proposed method consists 
									 of two stages: 9 the first one is to determine the image patches with normality by using 
									 the kurtosis test, the noise level is then estimated from these selected normal patches in the second stage...</p>
							</figcaption>
						</a>
					</li>

		
					<li>
						<a href="https://ieeexplore.ieee.org/abstract/document/9560022/">
							<figure>
								<img src="img/pupil.png"/>
							</figure>
							<figcaption>
								<p class="p1">Pupil-Contour-Based Gaze Estimation With Real Pupil Axes for Head-Mounted Eye Tracking</p>
								<p class="p2">Accurate gaze estimation that frees from glints and the slippage problem is challenging. 
									Pupil-contour-based gaze estimation methods can meet this challenge, except that the gaze accuracy is
									 low due to neglecting the pupil’s corneal refraction This article proposes a refraction-aware gaze estimation
									  approach using the real pupil axis, which is calculated from the virtual pupil image based on the derived
									   function between the real pupil ...</p>
							</figcaption>
						</a>
					</li>
					<li>
						<a href="http://openaccess.thecvf.com/content/CVPR2021/html/Xu_Adaptive_Rank_Estimate_in_Robust_Principal_Component_Analysis_CVPR_2021_paper.html">
							<figure>
								<img src="img/ARE.png"/>
							</figure>
							<figcaption>
								<p class="p1">Adaptive rank estimate in robust principal component analysis</p>
								<p class="p2">Robust principal component analysis (RPCA) and its variants have gained wide applications
									in computer vision. However, these methods either involve manual adjustment of some
									parameters, or require the rank of a low-rank matrix to be known a prior. In this paper, an
									adaptive rank estimate based RPCA (ARE-RPCA) is proposed, which adaptively assigns
									weights on different singular values via rank estimation. More specifically, we study the
									characteristics of the low-rank matrix, and develop an improved Gerschgorin disk theorem to ...</p>
							</figcaption>
						</a>
					</li>
					<li>
						<a href="https://www.osapublishing.org/abstract.cfm?uri=oe-29-9-12867">
							<figure>
								<img src="img/3Dreconstruction.jpg"/>
							</figure>
							<figcaption>
								<p class="p1">3D reconstruction of the specular surface using an iterative stereoscopic deflectometry method</p>
								<p class="p2">Phase measuring deflectometry (PMD) is an effective technique for three-dimensional measurement of specular surfaces.
									However, the ambiguity of monoscopic PMD and the time-consuming searching process of stereoscopic PMD are challenges for specular surface 
									reconstruction. To solve it, we propose an iterative reconstruction algorithm for the stereoscopic phase measuring deflectometry system free
									 of the time-consuming searching process for each pixel. An arbitrary seed point on the specular surface ...</p>
							</figcaption>
						</a>
					</li>
				</ul>
			</div>
			<div class="hd">
				<span class="prev"></span>
				<span class="next"></span>
			</div>
		</div>
	</div>
</div>

<div class="footer">
	<div class="w1240">
		<div class="div1 clearfix">
			<ul class="clearfix fr">
				<li><a href="index.html">首页</a></li>
				<li><a href="supervisor.html">负责人</a></li>
				<li><a href="direction.html">科研方向</a></li>
				<li><a href="publication.html">出版物</a></li>
				<li><a href="resource.html">资源</a></li>
				<li><a href="news.html">新闻</a></li>
				<li><a href="graduates.html">毕业生</a></li>
				<li><a href="index_en.html">English</a></li>
			</ul>
		</div>
		<div class="div2 clearfix">
			<div class="left fl">
				<p class="p2">
					友情链接:
					<a href="https://www.csail.mit.edu/" class="num">https://www.csail.mit.edu/</a>
					<a href="https://www.ri.cmu.edu/" class="num">https://www.ri.cmu.edu/</a>
					<a href="https://ai.stanford.edu/" class="num">https://ai.stanford.edu/</a>
					<a href="https://www.crcv.ucf.edu/" class="num">https://www.crcv.ucf.edu/</a>
				</p>
				<p class="p1">
					地址：武汉市青山区，武汉科技大学信息科学与工程学院，430081<br />
					Copyright©2022 人工智能与机器视觉实验室 版权所有<br />
					<a href="https://beian.miit.gov.cn/" target="_blank"  class="num">鄂ICP备2022008689号-1</a>
					
					<!-- <a href="https://beian.miit.gov.cn" class="num">备案号：鄂ICP备2022008689号-1</a> -->
				</p>
			</div>
			<div class="right fr">
				<p class="p3">联系方式</p>   
				<p class="p4"><a href="mailto:shiqian.wu@wust.edu.cn">shiqian.wu@wust.edu.cn</a></p>
			</div>					
		</div>
	</div>
</div>		




<script src="js/jquery.js"></script>
<script src="js/SuperSlide.js"></script>
<script src="js/plugin.js"></script>
<script src="js/banner.js"></script>
<script src="js/index.js"></script>		
<script src="js/more.js"></script>		
</body>
</html>
