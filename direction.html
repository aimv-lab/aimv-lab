<!DOCTYPE html>
<html lang="zh">
<head>
<meta charset="UTF-8">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width,initial-scale=1.0,user-scalable=no" />
<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black" />
<meta name="renderer" content="webkit" />
<meta name="screen-orientation" content="portrait" />
<meta name="x5-orientation" content="portrait" />
<title>AIMV Laboratory|Artificial Intelligence and Machine Vision</title>
<link rel="stylesheet" type="text/css" href="css/style.css"/>
</head>
<body>
	<div class="top clearfix">
		<div class="header-navbar">
			<a href="index.html" target="_blank" class="logo fl"><img src="img/logo.png" /></a>
			<ul class="navbar clearfix fl">
				<li><a href="index.html" style="font-size: 16px;">Home</a></li>
				<li><a href="supervisor.html" style="font-size: 16px;">Team</a></li>
				<li><a href="direction.html" style="font-size: 16px;">Research</a></li>
				<li><a href="publication.html" style="font-size: 16px;">Publication</a></li>
				<li><a href="resource.html" style="font-size: 16px;">Resource</a></li>
				<li><a href="news.html" style="font-size: 16px;">News</a></li>
				<li><a href="graduates.html" style="font-size: 16px;">Alumni</a></li>
				<li><a href="index_cn.html" style="font-size: 16px;">Chinese</a></li>
			</ul>
		</div>
	</div>


<div class="breadcrumb" >
	<div class="w1240 clearfix">
		<div class="div2 fl">
			<span><img src="img/home.png">Home</span><i>&gt;</i>
			<span class="on">Direction</span>
		</div>
	</div>	
</div>
<div class="fuwupage">
	<div class="w1240">
        <div class="direction_tab">
            <ul>
                <li class="direction_selected_tab" index="0">Theory</li>
                <li index="1">System</li>
                <li index="2">Product</li>
                <li index="3">project</li>
            </ul>
        </div>	


          <!-- re-id -->
          <div class="fuwupage-cont index_0 show_tab">
                            <div class="clearfix div">
                                <div class="r-cont fl">
                                    <div class="r-mask">
                                        <h3>Small group reidentification research</h3>
                                    </div>
                                    <img src="img/dirction/reid.png" alt=""  width="580px" height="450px"/>
                                </div>
                                <div class="l-cont fr">
                                    <h3>Small group reidentification research</h3>
                                    <div class="clearfix">
                                        <b></b>
                                    </div>	
                                    <h1><strong>Subject introduction</strong></h1>				
                                    <p>
                                        In order to solve the challenge of extracting stable features of small groups of people due to light changes in cross vision scenes, a light invariant optical flow preprocessing algorithm based on weighted regularization transformation was proposed. This algorithm can obtain light invariant optical flow estimation results in cross vision light changing scenes;
                                        To solve the problems of the lack of large-scale data sets for small group research in visible light scenes, as well as the differences in group characteristics caused by changes in visual fields,
                                        Through extensive recruitment of volunteers, a single mode visible light SYSU-Group dataset was constructed, and a twin network based SVIGR algorithm was proposed;
                                        To solve the time domain synchronization problem of multi perspective small group video,
                                        A multi perspective style transfer method based on self-supervised learning is proposed, which monitors the key points of learning objectives through potential correspondence between perspectives.
                                         The relevant results are as follows:
                                    </p>		
                                    <h1><strong>Research results</strong></h1>				
                                    <ul>
                                        <li class="new_honor">
                                            Ling Mei, Jianhuang Lai, Xiaohua Xie, Junyong Zhu, Jun Chen. Illumination-invariance optical flow estimation using weighted regularization transform. IEEE Transactions on Circuits and Systems for Video Technology(TCSVT), 30(2):495–508, 2020.
                                        </li>
                                        <li class="new_honor">
                                            Ling Mei, Jianhuang Lai, Zhanxiang Feng, Xiaohua Xie. From pedestrian to group retrieval via siamese network and correlation. Neurocomputing, 412:447–460, 2020.
                                        </li>
                                        <li class="new_honor">
                                            Ling Mei, Yizhuo He, Farnoosh Javadi Fishani, Yaowen Yu, Lijun Zhang, Helge Rhodin. Learning Domain-Adaptive Landmark Detection based Self-Supervised Video Synchronization for Remote Sensing Panorama. Remote Sensing, 15(4): 953, 2023.
                                        </li>
                                    </ul>
                                </div>
                            </div>				
          </div>


        <!-- low-light -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Low Light Image Enhancement</h3>
                    </div>
                    <img src="img/dirction/low-light.gif" alt=""  width="590px" height="340px"/>
                </div>
                <div class="l-cont fr">
                    <h3>Low Light Image Enhancement</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        Low-light images have always had the problems of low visibility and high noise, and the corresponding enhancement method is an ill-posed problem, mainly because there are many possibilities for mapping the enhanced output results. The processing of low-light images has been a hot topic in academia and industry in terms of providing better visualization for humans and revealing details for machine vision applications. To this end, the team nonlinearly maps the denoised low-light reconstructed image and illumination components into high-quality enhanced images through BTF according to the ideal exposure state. The research results have a wide range of application scenarios, such as machine vision, object tracking, and pedestrian re-identification
                         and HDR reconstruction etc.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            C. Zheng, Z. Li, Y. Yang and S. Wu, "Single image brightening via multi-scale exposure fusion with hybrid learning," IEEE Trans. Circuits and Systems for Video Technology , vol.31, no.4, pp.1425-1435, 2021.
                        </li>
                        <li class="new_honor">
                            W. Cao, S. Wu, D. Wang and J. Wu, "A High Visibility and SNR 
                            image from One Single-Shot Low-Light Image[J]." IEEE Computer Graphics and 
                            Applications. Vol. 41, no. 5, pp: 124-137, 2020.
                        </li>
                        <!-- <li class="new_honor">
                            Wei Cao, Shiqian Wu, Zhaoyi Liu, Dianwei Wang and Sos Agaian, Illumination Estimation via Sparse Bright Channel for Enhancing Under-exposed Images[J]. IEEE Transactions on Cybernetics.
                        </li> -->
                    </ul>
                </div>
            </div>				
        </div>

        <!-- dehaze -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Single Image Dehazing</h3>
                    </div>
                    <img src="img/dirction/dehaze.gif" alt=""  width="590px" height="340px"/>
                </div>
                <div class="l-cont fr">
                    <h3>Single Image Dehazing</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        The problem of noise amplification and loss of details is faced in the process of defogging a single image. To this end, the team decomposes the image into different scales, and then uses the Gaussian filtered image to calculate the atmospheric light component to avoid the influence of noise.
                        For the calculation of the transmittance, the initial value is firstly calculated through the dark pass prior, and then the initialized transmittance is refined using the prior knowledge of the non-local fog line, and then WFIG is used to further suppress the transmittance image noise. Finally, the multi-scale strategy is used to restore the image, which ensures the details of the dehazed image.
                           A large number of experiments show that the proposed algorithm has obvious advantages in noise suppression, detail enhancement, color fidelity and so on.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Li Z, Shu H, Zheng C. Multi-Scale Single Image Dehazing Using Laplacian and Gaussian Pyramids[J]. IEEE Transactions on Image Processing, 2021, 30: 9270-9279.
                        </li>
                       
                    </ul>
                </div>
            </div>				
        </div>

        <!-- derain -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>single image to rain</h3>
                    </div>
                    <img src="img/dirction/derain.gif" alt=""  width="590px" height="340px"/>
                </div>
                <div class="l-cont fr">
                    <h3>single image to rain</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        The rain removal algorithm based on image decomposition is easy to cause the loss of image details, which directly restricts the implementation of high-level vision tasks. For this reason, the team introduced the idea of denoising into the rain removal task based on the similarity between denoising and rain removal tasks. According to the attribute of local similarity in the internal blocks of the image, the network structure is designed using the idea of Non-Local, and the similar blocks are extracted for fusion and rain removal.
                         A large number of experiments show that the proposed algorithm retains the details of the image while removing the raindrops.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Zheng C, Li Z, Li Y, et al. Non-Local Single Image DE-Raining Without Decomposition[C]//ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021: 1425-1429.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <!-- repair -->
        <!-- <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>单张图像修补</h3>
                    </div>
                    <img src="img/dirction/repair.gif" alt=""  width="580px" height="350px"/>
                </div>
                <div class="l-cont fr">
                    <h3>单张图像修补</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        基于图像分解的去雨算法容易造成图像细节的丢失，直接制约高层视觉任务的实施。为此，团队根据去噪与去雨任务的相似性，把去噪的思想引入到去雨任务中。根据图像内在块存在局部相似性的属性，利用Non-Local的思想设计网络结构，提取相似块进行融合去雨。
                        大量实验表明所提出算法去掉雨滴的同时保留了图像的细节信息。
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Zheng C, Li Z, Li Y, et al. Non-Local Single Image DE-Raining Without Decomposition[C]//ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021: 1425-1429.
                        </li>
                    </ul>
                </div>
            </div>				
        </div> -->

        <!-- HDR -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>High Dynamic Video Processing</h3>
                    </div>
                    <img src="img/dirction/HDR.gif" alt="" width="590px" height="400px" />
                </div>
                <div class="l-cont fr">
                    <h3>High Dynamic Video Processing</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        This research direction uses image modeling, image mosaic, image fusion, image registration and other means to study the method of high dynamic video. The main research contents are:
                         1) Camera response function: The irradiance of the image and the irradiance of the scene have a nonlinear relationship. 
                         2) Moving target detection: process a large amount of video data in real time, analyze, locate and segment the target of interest, track the detected moving target, and analyze and identify the behavior of the target through tracking.
                         3) Image registration: matching and superimposing multiple images acquired at different times, different imaging devices or under different conditions.
                         4) Tone mapping: Perform a large contrast attenuation to change the brightness of the scene to a displayable range, while maintaining image details and colors, so that the obtained high-dynamic images can be displayed normally on the display.
                         5) Image synthesis: synthesize the obtained high dynamic background image and high dynamic target image to produce the result image that best meets the requirements.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            In recent years, this research direction has successively undertaken 1 project of the National Natural Science Foundation of China, a number of related application projects, and obtained a number of invention patents, including 2 US patents and 2 Singapore patents; published more than 20 in core academic journals. More than 10 high-level academic papers have been indexed by SCI, EI, and ISTP; two products have been developed on the mobile phone platform and the computer platform, and some of the results have been displayed on ACM Siggraph and ACM Siggraph Asia.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <!-- background -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Video front and background separation</h3>
                    </div>
                    <img src="img/dirction/background.gif" alt="" width="590px" height="400px" />
                </div>
                <div class="l-cont fr">
                    <h3>Video front and background separation</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        Foreground and background separation of video has always had changes in ambient lighting (sudden and slow changes in lighting), multimodality of the background (subtle movements in the background will affect the results of foreground target detection), shadows of moving objects , noise, new immobile objects entering the background (how to quickly adapt to background changes), how to accurately separate the background has always been a difficult problem.
To this end, according to the low-rank characteristics of the video background, the team proposed a low-rank decomposition algorithm based on rank estimation to achieve effective separation of the video foreground and background. The research results have a wide range of applications, such as target recognition, target tracking, pedestrian re-identification, etc.

                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
							Zhengqin Xu, Rui He, Shoulie Xie, Shiqian Wu. Adaptive Rank Estimate in Robust Principal Component Analysis[C]. 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2021.
						</li>
						<li class="new_honor">
							Zhenqin Xu, Huasong Xing, Shun Fang, Shiqian Wu, Shoulie Xie. Double-Weighted Low-Rank Matrix Recovery Based on Rank Estimation[C]. 2021 IEEE/CVF International Conference on Computer Vision Workshops. 2021.							
						</li>
                    </ul>
                </div>
            </div>				
        </div>

        <!-- blurnet -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Dynamic Fuzzy Neural Network</h3>
                    </div>
                    <img src="img/DFNN.PNG" alt="" width="600px" height="350px" />
                </div>
                <div class="l-cont fr">
                    <h3>Dynamic Fuzzy Neural Network</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        Based on the theory of fuzzy neural network, this research direction is used to solve the problem of how to quickly and automatically construct an effective fuzzy neural network in the absence of comprehensive knowledge of fuzzy theory, neural network and application objects. The main research contents include:
                         1) The structure of dynamic fuzzy neural network.
                         2) The structure and parameters are determined simultaneously.
                         3) The learning method of dynamic fuzzy neural network: rule generation criterion, hierarchical learning idea, premise parameter assignment, result parameter determination, pruning technique, and structure identification and division of input space.
                         4) Realization of different algorithms of dynamic fuzzy neural network: singular value decomposition method, eigenvalue decomposition method, column pivot method and total least squares method in pruning technology, and extended Kalman filter method in parameter adjustment method.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            In recent years, this research direction has undertaken and completed a number of related application projects, published 2 monographs, published more than 50 high-level academic papers in core academic journals at home and abroad, and more than 20 papers were included by SCI, EI, and ISTP. Among them, the article "Dynamic Fuzzy Neural Network: A New Method of Function Approximation" was cited 392 times.                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <!-- pr -->
        <div class="fuwupage-cont index_0 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Pattern recognition</h3>
                    </div>
                    <img src="img/face.PNG" alt="" width="580px" height="320px" />
                </div>
                <div class="l-cont fr">
                    <h3>Pattern recognition</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        This research direction is based on the theory of pattern recognition, using artificial intelligence technology, image enhancement, deep learning and other means to study methods to meet special performance requirements. The main research contents are:
                         1) Recognition of face, gender, age, etc.: process the face images imaged under different lighting conditions, eliminate the influence of light, enhance the local texture information of the face, and improve the recognition accuracy in face recognition applications. The gender is judged according to the input face image, and the FLD method is improved so that the ratio of the class distance to the intra-class distance is infinite, so as to obtain the most effective gender discrimination feature without intersection. Determine the age range of the input face image.
                         2) Character recognition: According to the characteristics of characters, design and research reasonable image preprocessing algorithms, study the normalization and refinement processing methods of characters, and establish character standard feature databases.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            In recent years, this research direction has successively undertaken and completed 3 projects of the National Natural Science Foundation of China and Jiangxi Provincial Natural Science Foundation of China, as well as a number of related application projects, obtained 2 invention patents, and published more than 30 high-level articles in core academic journals at home and abroad. Level academic papers, more than 20 articles were included by SCI, EI, ISTP, among which the article "Blood Flow Model of Human Face Thermogram and Its Application in Face Recognition" was listed as an article in the field of machine learning and pattern recognition by Microsoft Academic Search top article.
                                                </li>
                    </ul>
                </div>
            </div>				
        </div>



        <!-- car -->
        <!-- <div class="fuwupage-cont index_1 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>车辆超限测量系统</h3>
                    </div>
                    <img src="img/shijue.png" alt=""  width="600px" height="400px"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="car.html">车辆超限测量系统</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        车辆轮廓尺寸与重量超限判定对交通系统愈发重要：
                        （1）针对车辆尺寸超限判定，本项目采用双目视觉测量车辆长、宽、高，代替传统的激光雷达技术，成本低、鲁棒性强、精度高、且可视化程度高：利用高斯混合模型，解决车辆的实时检测与跟踪问题；改进稀疏特征点检测，提升系统鲁棒性；评估与提升双目标定、水平面标定等模块的性能，实现高精度的车辆尺寸估计。
                        （2）针对车辆重量超限判定，本项目利用单目视觉计算车轮轴数并判定车轮单双胎，从而确定货车车型与理论承重值，成本低、鲁棒性强：采用Hough圆变换与傅里叶-梅林变换检测车轮；利用卡尔曼滤波跟踪车轮位置，计算轴数；结合深度学习Resnet，分类车轮为单胎或双胎；Research results已应用于公路收费站的货车轴型识别与超重判定。
                    </p>		
                    <h1><strong>课题支持</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            2022年：基于双目视觉的车辆尺寸测量（南昌众加利公司）
                        </li>
                    </ul>
                </div>
            </div>				
        </div> -->

        <!-- eye_track -->
        <div class="fuwupage-cont index_1">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Head Mounted Eye Tracking System</h3>
                    </div>
                    <img src="img/eye_track.png" alt=""  width="585px" height="350px"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="eye.html">Head Mounted Eye Tracking System</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
            
                        Eye tracking is an important means to capture visual attention and then interpret intentions. This subject designs a head-mounted eye tracking system for the limitations of current EMG and EEG signals:
                         (1) A robust pupil detection algorithm is proposed; (2) The hardware is designed and implemented; (3) The corresponding software is developed using Qt, including the necessary software functions;
                         (4) Completed the necessary algorithms required by the system, such as personal calibration, algorithms from gaze direction to gaze point, reflective point detection, and target reconstruction.
                         Through the above research, it provides a theoretical basis and scientific basis for human-computer interaction driven by human vision, and enriches the connotation of natural human-computer interaction, which has important academic significance and application value.
                    
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Z. Wan, C. Xiong, W. Chen, H. Zhang and S. Wu, “Pupil-contour-based gaze estimation with real pupil axes for head-mounted eye tracking,” IEEE Trans. Industrial Information , 2022, 18(6): 3640-3650.
                        </li>

                        <li class="new_honor">
                            Z. Wan,  C. Xiong, W. Chen, and H. Zhang. Robust and Accurate Pupil Detection for Head-Mounted Eye Tracking. Computers & Electrical Engineering, 2021, 93: 107193.   
                        </li>

                        <!-- <li class="new_honor">
                            Z. Wan,  C. Xiong, Li Quanlin, Chen Wenbin, Wong Kelvin Kian Loong and Wu Shiqian. Accurate Regression-Based 3D Gaze Estimation Using Multiple Mapping Surfaces. IEEE Access, 2020, 8: 166460–166471.
      
                        </li> -->
                        
                    </ul>
                </div>
            </div>				
        </div>


        <!-- fenjian -->
        <div class="fuwupage-cont index_1">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Intelligent Sorting System</h3>
                    </div>
                    <img src="img/fenjian.jpg" alt=""  width="600" height="350"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="sorting.html">Intelligent Sorting System</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        With the rapid development of the domestic economy, great changes have taken place in the logistics industry. The traditional manual sorting cannot meet the market demand, and the sorting business is developing towards the direction of automatic sorting. The existing intelligent sorting system has shortcomings such as low accuracy, long time consumption, and poor applicability, and cannot meet the increasingly complex actual industrial scenarios. To this end, the team optimized the algorithm of the hand-eye calibration, pose estimation, path planning and other links of the intelligent sorting system, and realized high-precision and fast intelligent sorting in the industrial Bin-Picking scene, which provided a basis for the design of intelligent sorting systems at home and abroad. A new technical solution is provided. The research results have broad application prospects in logistics sorting, automobile assembly and other fields.
                                        </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Cui X, Yu M, Wu L, et al. A 6D Pose Estimation for Robotic Bin-Picking Using Point-Pair Features with Curvature (Cur-PPF)[J]. Sensors, 2022, 22(5): 1805.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

        <!-- SLAM -->
        <div class="fuwupage-cont index_1">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Visual SLAM system</h3>
                    </div>
                    <img src="img/SLM.jpg" alt=""  width="580px" height="350px"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="SLAM.html">Visual SLAM system</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        SLAM is synchronous positioning and mapping, which can build a map of the surrounding environment and estimate its own motion during the camera movement. SLAM algorithms have broad application prospects in unmanned driving, service robots, surveying and mapping, AR and other scenarios. Traditional visual SLAM algorithms track based on the assumption that the environment is static, which is less robust in dynamic environments and does not make full use of image information.
                         To this end, the team combined semantic segmentation technology with SLAM to build a semantic map of the environment while improving the robustness of the algorithm to help the robot better understand the surrounding environment.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            胡年宗, 伍世虔, 张亦明. 基于卷积神经网络的SLAM回环检测算法研究[J]. 计算机仿真,2020,37(05):282-286.
                        </li>
                        <li class="new_honor">
                            Wang J, Wu S, Li H, et al. Path planning combining improved rapidly-exploring random trees with dynamic window approach in ROS[C]//2018 13th IEEE Conference on Industrial Electronics and Applications (ICIEA). IEEE, 2018: 1296-1301.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>


         <!-- 三维结构光重建系统 -->
         <div class="fuwupage-cont index_1">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>3D Structured Light Reconstruction System</h3>
                    </div>
                    <img src="img/3DCX.png" alt=""  width="580px" height="350px"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="3DCX.html">3D Structured Light Reconstruction System</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        With the rapid development of science and technology today, three-dimensional information has gradually become a means for human beings to understand and transform the world. As a 3D reconstruction method with a wide range of applications and deep theoretical research, structured light has always been a research hotspot. The structured light system pursues high precision, high efficiency and low cost, so the team proposed efficient and robust improved algorithms for the calibration method, pattern coding, and phase unwrapping in the measurement of the structured light system. For the reconstruction of structured light in special environments, the team proposed solutions for highly reflective parts and specularly reflective objects.
                         It is of great significance to the industrialization of factories. The Research results have great development prospects and uses in industrial testing and consumer entertainment.
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <!-- <li class="new_honor">
                            Han Hao, Wu Shiqian, Song Zhan. Curved LCD based deflectometry method for specular surface measurement[J]. Optics and Lasers in Engineering. 2022, 151: 106909. 
                        </li> -->
                        <li class="new_honor">
                            Han Hao, Wu Shiqian, Song Zhan, et al. 3D reconstruction of the specular surface using an iterative stereoscopic deflectometry method[J]. Optics Express, 2021,29(9): 12867-12879.    
                        </li>
                        <li class="new_honor">
                            Deng, G., Wu, S., Zou, L., Cao, W., & Han, H. Robust gamma correction based on chord distribution coding considering projector defocusing. Applied Optics, 2022,61(10): 2842-2849.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>

       <!-- 字符识别系统 -->
       <div class="fuwupage-cont index_1">
        <div class="clearfix div">
            <div class="r-cont fl">
                <div class="r-mask">
                    <h3>Character recognition system</h3>
                </div>
                <img src="img/text.png" alt=""  width="580px" height="400px"/>
            </div>
            <div class="l-cont fr">
                <h3><a href="text.html">Character recognition system </a></h3>
                <div class="clearfix">
                    <b></b>
                </div>	
                <h1><strong>Subject introduction</strong></h1>				
                <p>
                    Using image processing and pattern recognition theories and methods, combining traditional methods with deep learning, researching character recognition methods in natural scenes, and developing embedded character recognition systems based on Internet of Things technology.
                     It has broad application prospects in detonator code recognition, instrument reading recognition/remote meter reading, license plate recognition, container number recognition, natural scene text recognition, etc.
                </p>	
                <h1><strong>Projects</strong></h1>				
                <ul>

                    <li class="new_honor">
                        Internet of Things smart meter reading image recognition engine research and development, school-enterprise horizontal cooperation project, 2022-2023.
                    </li>
                    <li class="new_honor">
                        Research on Image Meter Reading Technology for Inspection Intelligent Robots in Complex Scenes, Engineering Research Center of Metallurgical Automation and Detection Technology, Ministry of Education, 2021-2022.
                    </li>
                </ul>	
                <h1><strong>Research results</strong></h1>				
                <ul>

                    <li class="new_honor">
                        A laser etching industrial detonator code image positioning and correction method [P]. ZL201810667817.2 (invention patent)
                    </li>
                    <li class="new_honor">
                        A laser-etched metal detonator code character segmentation method based on image processing [P]. ZL201810748680.3 (invention patent)
                    </li>
                    <li class="new_honor">
                        An automatic reading method of pointer meters based on improved semantic segmentation network [P]. CN202111365897.4 (invention patent)                    </li>
                    <li class="new_honor">
                        An automatic reading method of pointer meters based on improved semantic segmentation network [P]. CN202111365897.4 (invention patent)
                    </li>
                    <li class="new_honor">
                        基于卷积神经网络的字轮式仪表双半字符识别[J]. 武汉科技大学学报, 2021, 44(01): 68-73 
                    </li>
                </ul>
            </div>
        </div>				
       </div>

       <!-- 特定目标和行为智能监控系统 -->
       <div class="fuwupage-cont index_1">
        <div class="clearfix div">
            <div class="r-cont fl">
                <div class="r-mask">
                    <h3>Specific target and behavior intelligent monitoring system</h3>
                </div>
                <img src="img/dirction/image129.png" alt=""  width="580px" height="400px"/>
            </div>
            <div class="l-cont fr">
                <h3><a href="monitor.html">Specific target and behavior intelligent monitoring system </a></h3>
                <div class="clearfix">
                    <b></b>
                </div>	
                <h1><strong>Subject introduction</strong></h1>				
                <p>
                    Using Internet of Things technology and machine vision technology to collect image or video data, intelligently detect specific targets and behaviors based on deep learning methods, and can be deployed on the cloud or terminal to meet the needs of various application scenarios.
                     Typical application scenarios:
                     (1) All-weather pedestrian detection, face detection, vehicle detection, and fireworks detection in the monitoring area;
                     (2) Smoking and mobile phone behavior detection at gas stations, laboratories, and factory sites;
                     (3) Detection of illegal driving behaviors, such as fatigue detection (closed eyes, yawning, dozing off, etc.), making phone calls, and inattention.

                </p>	
                <h1><strong>Projects</strong></h1>				
                <ul>

                    <li class="new_honor">
                        Research and development of crane driver behavior monitoring and early warning system. School-enterprise horizontal cooperation project, 2022-2023.
                    </li>
                   
                </ul>	
                <h1><strong>Research results</strong></h1>				
                <ul>

                    <li class="new_honor">
                        A smoking and phone call detection method based on deep learning and behavior prior [P]. CN201910970860.0 (invention patent)
                    </li>
                    <li class="new_honor">
                        基于人脸特征点分析的疲劳驾驶实时检测方法[J].电视技术, 2018, 42(12): 27-30.  
                    </li>
                    <li class="new_honor">
                        基于弱显著图的实时热红外图像行人检测[J]. 红外技术, 2021, 43(07): 658-664.  
                    </li>
                    
                </ul>
            </div>
        </div>				
       </div>



         <!-- 3D打印 -->
        <div class="fuwupage-cont index_2">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Full color 3D printing</h3>
                    </div>
                    <img src="img/3D.png" alt=""  width="600" height="350"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="3dprint.html">Full color 3D printing</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        With the advent of the industrial "5.0" era, personalized customization has been pushed into the wave of the times, and monochrome 3D printing technology has been difficult to meet the diverse and personalized needs of users. The SLA full-color 3D printers that have been put into use on the market are bulky, expensive, and complicated to operate, and cannot satisfy more and more individual users. To this end, the team solved challenging problems such as uneven mixing of consumables, narrow color coverage, and low color accuracy by designing a new type of mixing nozzle, developing a color mixing scheme for consumables, and improving the 3D printing control system. Design and manufacturing provides a new technical solution, which plays an important role in promoting the development of full-color 3D printing technology. Research results have broad development prospects and huge development potential in the fields of cultural creativity, medical and health care, cultural heritage restoration, and remote sensing mapping.                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Jiang Binchen, Luo Mingling, Zhou Qihong, etc. A multi-input and one-out 3D printing color mixing nozzle that can be equipped with a camera [P]. China, 202011309141.3, 2020-11-20.                        </li>
                        <li class="new_honor"> 
                            Jiang Binchen, Luo Mingling, Zhang Yunxuan, etc. A Color 3D Printer with a Test Platform [P]. China, 202120369182.5, 2021-02-08.                        </li>
                        <li class="new_honor">
                            Luo Mingling, Jiang Binchen, Liu Zhen, etc. A preparation method of full-color 3D printing consumables [P]. China, 202110583697.X, 2021-05-27.                        </li>
                    </ul>
                </div>
            </div>				
        </div>


        <!-- 智能相机 -->
        <div class="fuwupage-cont index_2">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Smart camera</h3>
                    </div>
                    <img src="img/dirction/image150.png" alt=""  width="590" height="320"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="camera.html">Smart camera</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        In order to reduce the cost and space occupancy of the entire machine vision system, the team integrated the image acquisition unit, image processing unit, and analysis unit into an overall device based on an embedded platform, and finally developed a complete set covering hardware systems, software systems, Smart vision system for user interface.
                         The whole system involves the control and deployment of the light source system, the overall construction and integration of the vision system, and the research and design of the system function algorithm. At the same time, the follow-up function expansion of the vision system needs to be considered, and the system function can be customized according to different application scenarios.
                         Nowadays, the embedded vision system has the characteristics of good portability, high cost performance, low power consumption, high reliability and easy programming, etc., and has become the main direction of the development of the vision system. significance.
                       
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Low-light image enhancement and acceleration processing based on ZYNQ[J]. The China Automation Congress 2021.
                        </li>
                        <li class="new_honor"> 
                            视频实时去雾的硬件优化设计[J]. 仪表技术与传感器，2021.
                        </li>
                        <li class="new_honor">
                            A high-frequency time-sharing exposure light source controller. Invention patent, patent number: 202110095980.8.                        </li>
                    </ul>
                </div>
            </div>				
        </div>




         <!-- 爆破优化预测软件 -->
         <div class="fuwupage-cont index_2">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>Blasting Optimization Prediction Software</h3>
                    </div>
                    <img src="img/dirction/bao.jpg" alt=""  width="580" height="320"/>
                </div>
                <div class="l-cont fr">
                    <h3><a href="explode.html">Blasting Optimization Prediction Software</a></h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        Domestic research on intelligent optimization and prediction systems for blasting is less, and there are problems such as backward technology and low efficiency. There is an urgent need for a good solution to use artificial intelligence technology and computer-aided design in blasting engineering to meet the production requirements for high-quality blasting effects. Require.
                         This project takes the open-pit mine step loosening blasting as the research object, and develops a set of artificial intelligence-based blasting optimization and prediction software system: on the basis of realizing AI prediction and optimization, it embeds the empirical formula commonly used in the industry, and realizes the prediction and optimization based on artificial intelligence. It is an international commercial software system that meets the needs of various usage scenarios at the same time.
                         The system meets the main performance indicators of commercial software such as stability, compatibility, and safety, and the blasting optimization prediction results meet the design requirements of on-site blasting, and achieve the goal of formal use in China and formal trials abroad.
                    </p>	
                    <h1><strong>Subject support</strong></h1>	
                    <ul>
                        <li class="new_honor"> 
                            2020.7-2022.7: Research and development of open-pit blasting optimization and prediction software (Beijing Auxin Chemical Technology Development Co., Ltd.)                        </li>
                    </ul>
                    <h1><strong>Research results</strong></h1>	

                    <ul>
                        <li class="new_honor">
                            Completion of blasting optimization prediction software that meets the international market requirements                        </li>
                    </ul>
                </div>
            </div>				
        </div>
      
        <div class="fuwupage-cont index_3">
            <div class="clearfix div">
                <div class="about-sec1 project">
                    <div class="ab1 " id="ab4" style="background:#fff;">
                        <div class="about-tit">
                            <h3>project</h3>
                        </div>
                        <ul class="clearfix project-list">    
                            
                            <li>
                                2021.11-2022.11: Machine vision-based vehicle profile measurement (450,000), project leader
                            </li>
                            <li>
                                2020.11-2022.11: Development of supercapacitor energy verification system (300,000), project leader.
                            </li>
                            <li>
                                2020.7-2022.7: Open-pit blasting optimization and prediction software research and development (Beijing Auxin Chemical Technology Development Co., Ltd., 1.85 million), project leader.
                            </li>
                            <li>
                                2019.6-2019.12: 3C industry robot image processing algorithm test (50,000), project leader.
                            </li>
                            <li>
                                2019.6-2019.12: Metal product surface defect detection technology (50,000), project leader.
                            </li>
                            <li>
                                2019.1-2020.12: Research on key technologies of face recognition under extreme light conditions (No. D20191104, 40,000), a key project of the scientific research plan of the Hubei Provincial Department of Education, team member
                            </li>
                            <li>
                                2019.1-2021.12: On-line adaptive research on leg impedance of galloping gait of quadruped robot under unknown ground conditions (National Natural Science Foundation of China, No.51805381, 260,000), team member.
                            </li>
                            <li>
                                2019.1-2021.12: Research on adaptive recognition of industrial product surface defect images with shared and proprietary features (National Natural Science Foundation of China, No. 51805386, 180,000), team member.
                            </li>
                            <li>
                                2019.1-2021.12: Flexible Intelligent Industrial Robot Automated Logistics Sorting System Based on Visual and Force Sense Perception, Hubei Province Technological Innovation Major Project (No. ZDCX2019000025, 200,000), sub-project leader.
                            </li>
                            <li>
                                2018.1-2021.12: Research on fast 3D measurement technology of multi-camera and multi-projection structured light based on multipath effect (National Natural Science Foundation of China, No. 61775172), project leader
                            </li>
                            <li>
                                2015.10-2017.10: Research on anonymous video analysis technology for intelligent advertisement push (Jiangxi Provincial Digital Media Engineering Technology Research Center, project number K0361401), project leader.
                            </li>
                            <li>
                                2014.1-2017.12: High dynamic range of surveillance video and its processing in the radiation domain (National Natural Science Foundation of China, No. 61371190, 740,000), project leader.
                            </li>
                            <li>
                                2011-2013: Research on Motion Time Domain Filtering Technology Based on Scene Switching and Adaptive GOP Structure (Science and Technology Project of Jiangxi Provincial Department of Education, No. GJJ11414), Project Leader.
                            </li>
                            <li>
                                2009-2012: Research on Robust Biometric Feature Extraction of Infrared Face Based on Biothermal Transfer (Jiangxi Provincial Department of Education Science and Technology Project, No: GJJ09296), project leader.
                            </li>
                            <li>
                                2006-2009: Research on robust biometric feature extraction in far-infrared face recognition under abnormal conditions (National Natural Science Foundation of China, No. 60665001), project leader.
                            </li>
                            <li>
                                2006-2009: Research on the theory and system of infrared face recognition based on biomechanics (Natural Science Foundation of Jiangxi Province, No. 0611025), project leader.
                            </li>
                            <li>
                                1993-1995: Underwater robot modeling, control and simulation (pre-research project of the Commission of Science, Technology and Industry for National Defense), project leader.
                            </li>
                            
                            <li>
                                1991-1995: Machine Tool Modular Manufacturing Technology (Seventh Five-Year Plan Project of the State Planning Commission), head of the "Machine Tool Performance Evaluation" sub-project
                            </li>
            
                        </ul>
            
                    </div>
                </div>
            </div>
        </div>

                       


        

        <!-- <div class="fuwupage-cont index_1 show_tab">
            <div class="clearfix div">
                <div class="r-cont fl">
                    <div class="r-mask">
                        <h3>机器人技术</h3>
                    </div>
                    <img src="img/robot.png" alt="" width="600px" height="300px" />
                </div>
                <div class="l-cont fr">
                    <h3>机器人技术</h3>
                    <div class="clearfix">
                        <b></b>
                    </div>	
                    <h1><strong>Subject introduction</strong></h1>				
                    <p>
                        本研究方向是以人工智能机器人技术为理论基础，结合肢体运动、视觉系统等多种手段研究满足特殊性能要求的方法。主要进行
                        步态动态特性分析，建立四足疾驰步态下的混杂动态模型。系统动力学模型沿周期轨道投影到与周期轨道正交的截面上，
                        将非线性的奔跑步态模型转化为具有周期特性的时变线性系统模型。根据四足机器人周期被动步态的运动轨迹，利用多项式拟合的方法将轨迹作为虚拟约束施加到实际四足机器人上，实现相应步态。
                    </p>		
                    <h1><strong>Research results</strong></h1>				
                    <ul>
                        <li class="new_honor">
                            Q. Y. Liu, X. D. Chen, B. Han, X. Lou, “Virtual Constraint Based Control of Bounding Gait of Quadruped Robots,” Journal of Bionic Engineering, 2017, 14(2):218–231.
                        </li>
                    </ul>
                </div>
            </div>				
        </div>
    -->

    </div>
</div>

<div class="footer">
	<div class="w1240">
		<div class="div1 clearfix">
			<ul class="clearfix fr">
                <li><a href="index.html">Home</a></li>
                <li><a href="supervisor.html" >Team</a></li>
                <li><a href="direction.html" >Research</a></li>
                <li><a href="publication.html">Publication</a></li>
                <li><a href="resource.html" >Resource</a></li>
                <li><a href="news.html" >News</a></li>
                <li><a href="graduates.html" >Alumni</a></li>
                <li><a href="index_cn.html" >Chinese</a></li>
			</ul>
		</div>
		<div class="div2 clearfix">
			<div class="left fl">
                <p class="p2">
                    Useful link:
                    <a href="https://www.csail.mit.edu/" class="num">https://www.csail.mit.edu/</a>
                    <a href="https://www.ri.cmu.edu/" class="num">https://www.ri.cmu.edu/</a>
                    <a href="https://ai.stanford.edu/" class="num">https://ai.stanford.edu/</a>
                    <a href="https://www.crcv.ucf.edu/" class="num">https://www.crcv.ucf.edu/</a>
                </p>
				<p class="p1">
					School of Information Science and Engineering, Wuhan University of Science and Technology
					<br />
					Address: 947 Heping Avenue, Qingshan District, Wuhan 430081, Hubei, P.R. China
					<br />
					Copyright©2022 Artificial Intelligence and Machine Vision Lab<br />
					<a href="https://beian.miit.gov.cn" class="num">EICP No.2022008689-1</a>
				</p>
			</div>
			<div class="right fr">
				<p class="p3">E-mail</p>   
				<p class="p4"><a href="mailto:shiqian.wu@wust.edu.cn">shiqian.wu@wust.edu.cn</a></p>
			</div>					
		</div>
	</div>
</div>			


<script src="js/jquery.js"></script>
<script src="js/SuperSlide.js"></script>
<script src="js/plugin.js"></script>
<script src="js/banner.js"></script>
<script src="js/index.js"></script>
<script src="js/more.js"></script>
<script src="js/direction.js"></script>
</body>
</html>